---
title: "Analysis of Airline Safety Dataset"
author: "Frederick Jones"
output:
  html_document:
    df_print: paged
  pdf_document: default
---

### Data Preparation

```{r setup, echo=TRUE, results='hide', warning=FALSE, message=FALSE}
library(tidyverse)


```


### Motivation

1. Motivation:
The motivation behind this analysis goes beyond simple counts of accidents and incidents. We aim to delve into the rates of accidents, such as accidents per 100,000 flight miles. This metric allows us to account for changes in flight activity over time. For instance, if the number of miles flown doubles, but the accident count only increases by 20%, it could indicate an improvement in flight safety.


This approach aligns with industry best practices and allows for a more nuanced evaluation of safety measures, providing valuable insights for both the aviation industry and the broader public. Our goal is not only to identify patterns but also to contribute to the ongoing efforts to enhance aviation safety and inform decision-making in the industry.


### Data collection 

The dataset is hosted on kaggle so we are using from kaggle



### Type of study 

Additionally, we will explore various metrics beyond accident counts, including rates of fatalities and potentially other criteria. By examining these multiple dimensions, we can gain a more holistic understanding of airline safety and identify trends that might be obscured by raw counts alone.


### Data Source 

The data set has been made available by kaggle at the following [link](https://www.kaggle.com/datasets/fivethirtyeight/fivethirtyeight-airline-safety-dataset)

### Dataset Descriptions
airline ----------------->	Airline (asterisk indicates that regional subsidiaries are included)
avail_seat_km_per_week ---->	Available seat kilometers flown every week
incidents_85_99	----------->Total number of incidents, 1985–1999
fatal_accidents_85_99------>	Total number of fatal accidents, 1985–1999
fatalities_85_99	-------->Total number of fatalities, 1985–1999
incidents_00_14 ---------->	Total number of incidents, 2000–2014
fatal_accidents_00_14----->	Total number of fatal accidents, 2000–2014
fatalities_00_14--------->	Total number of fatalities, 2000–2014




### Relevant summary statistics 

#### Import Dataset
```{r}
# Load necessary libraries
library(readr)

# Load the dataset
dataset  <- read_csv("airline-safety_csv.csv")
head(dataset)

```


```{r}
# Summary statistics
summary(dataset)
```
```{r}

# Checking missing values
sapply(dataset, function(x) sum(is.na(x)))

# Visualizing missing values

library(naniar)
gg_miss_var(dataset)

```




```{r}
# Assuming your dataset is stored in the 'dataset' variable

# Check for missing values
missing_values <- sapply(dataset, function(x) sum(is.na(x)))

# Identify columns with missing values
columns_with_missing <- names(which(missing_values > 0))

# Impute missing values using mean for numeric columns
for (col in columns_with_missing) {
  if (is.numeric(dataset[[col]])) {
    mean_value <- mean(dataset[[col]], na.rm = TRUE)
    dataset[[col]][is.na(dataset[[col]])] <- mean_value
  } else {
    # If it's a non-numeric column, you might use another strategy like imputing with the most frequent value
    most_frequent_value <- names(sort(table(dataset[[col]], decreasing = TRUE)))[1]
    dataset[[col]][is.na(dataset[[col]])] <- most_frequent_value
  }
}

# Verify that missing values are filled
sapply(dataset, function(x) sum(is.na(x)))


```



```{r}
head(dataset)
```






```{r}
# Calculate accidents per 100,000 flight miles
dataset$accidents_per_100k_miles <- 
  (dataset$fatal_accidents_85_99 + dataset$fatal_accidents_00_14) / 
  (dataset$avail_seat_km_per_week / 100000)

# Visualize accidents per 100,000 flight miles
hist(dataset$accidents_per_100k_miles, 
     main = "Accidents per 100,000 Flight Miles",
     xlab = "Accidents per 100,000 Miles")


```

```{r}
# Calculate a new metric, e.g., fatalities per incident
dataset$fatalities_per_incident <- 
  (dataset$fatalities_85_99 + dataset$fatalities_00_14) / 
  (dataset$incidents_85_99 + dataset$incidents_00_14)

plot(dataset$incidents_85_99 + dataset$incidents_00_14, 
     dataset$fatalities_per_incident,
     main = "Fatalities per Incident",
     xlab = "Total Incidents",
     ylab = "Fatalities per Incident")

```

```{r}
# Perform statistical analysis on the new metric
t_test_result <- t.test(dataset$fatalities_per_incident)
print(t_test_result)

```







```{r}
# Create a scatter plot of accidents over time
plot(dataset$incidents_85_99 + dataset$incidents_00_14, 
     dataset$avail_seat_km_per_week, 
     main = "Accidents Over Time",
     xlab = "Accidents",
     ylab = "Available Seat Kilometers (in 100 million)")

```



```{r}
# Boxplot for selected columns
boxplot(dataset[, c("avail_seat_km_per_week", "incidents_85_99", "fatal_accidents_85_99", "fatalities_85_99")])

# Identify outliers using z-scores
outliers <- as.data.frame(boxplot.stats(dataset$avail_seat_km_per_week)$out)
outliers
```
```{r}
# Assuming your dataset is stored in the 'dataset' variable

# Define lower and upper percentiles
lower_percentile <- 0.05
upper_percentile <- 0.95

# Identify numeric columns for outlier removal
numeric_columns <- sapply(dataset, is.numeric)

# Loop through numeric columns and remove outliers
for (col in names(numeric_columns)[numeric_columns]) {
  lower_limit <- quantile(dataset[[col]], lower_percentile, na.rm = TRUE)
  upper_limit <- quantile(dataset[[col]], upper_percentile, na.rm = TRUE)
  
  # Remove outliers
  dataset[[col]] <- ifelse(dataset[[col]] < lower_limit, NA,
                           ifelse(dataset[[col]] > upper_limit, NA, dataset[[col]]))
}

# Verify that outliers are removed
summary(dataset)

```



```{r}

# Assuming you want to impute missing values with the mean for numeric columns
library(dplyr)

dataset <- dataset %>%
  mutate(across(where(is.numeric), ~ifelse(is.na(.), mean(., na.rm = TRUE), .)))
# Assuming you want to remove rows with any missing values
dataset <- na.omit(dataset)

# Correlation matrix
cor_matrix <- cor(dataset[, c("avail_seat_km_per_week", "incidents_85_99", "fatal_accidents_85_99", "fatalities_85_99")])

# Visualization of correlation matrix

library(corrplot)
corrplot(cor_matrix, method = "circle", type = "upper", order = "hclust")

```



```{r}

# Min-Max Scaling
min_max_scaling <- function(x) {
  (x - min(x)) / (max(x) - min(x))
}

# Apply Min-Max Scaling to numeric columns
dataset <- as.data.frame(lapply(dataset[, -1], min_max_scaling))

# Add back the 'airline' column
dataset$airline <- dataset$airline

# Display the normalized data
print(dataset)
```



```{r}

# Install and load the necessary library

library(caTools)

set.seed(123)  # Set seed for reproducibility
split <- sample.split(dataset$incidents_00_14, SplitRatio = 0.7)

train_data <- subset(dataset, split == TRUE)
test_data <- subset(dataset, split == FALSE)


```


```{r}
# Decision Tree with limited depth
library(rpart)
library(randomForest)
dt_model_fast <- rpart(incidents_00_14 ~ ., data = train_data, method = "class", maxdepth = 10)

# Random Forest
rf_model_fast <- randomForest(incidents_00_14 ~ ., data = train_data, ntree = 100)

# Predictions on the test set
dt_predictions_fast <- predict(dt_model_fast, test_data, type = "class")
rf_predictions_fast <- predict(rf_model_fast, test_data)

# Confusion Matrix
confusion_matrix_dt_fast <- table(dt_predictions_fast, test_data$incidents_00_14)
confusion_matrix_rf_fast <- table(rf_predictions_fast, test_data$incidents_00_14)

# Compare Confusion Matrices
print("Confusion Matrix for Faster Decision Tree:")
print(confusion_matrix_dt_fast)
print("Confusion Matrix for Random Forest:")
print(confusion_matrix_rf_fast)


```


### Conclusion

When It comes to the total number of fatalities based on the data set I relied on the T-test to give me the answer and the results are below.

    Data Information:
        Data: dataset$fatalities_per_incident
        Sample Mean: 19.49996

    T-Test Results:
        t-Value: 4.744
        Degrees of Freedom (df): 54
        p-Value: 1.575e-05 (very small)

    Confidence Interval:
        95% Confidence Interval: (11.25900, 27.74091)

    Hypothesis Testing:
        Null Hypothesis ($H_0$): The true mean of fatalities_per_incident is equal to 0.
        Alternative Hypothesis ($H_a$): The true mean of fatalities_per_incident is not equal to 0.

    Interpretation:
        The t-test statistic (4.744) is associated with a very small p-value (1.575e-05), which is below the commonly used significance level of 0.05.
        Therefore, you would reject the null hypothesis.
        The 95% confidence interval (11.25900, 27.74091) indicates the range within which you are reasonably confident the true mean of fatalities_per_incident lies.

In conclusion, based on this t-test, there is evidence to suggest that the true mean of fatalities_per_incident is significantly different from 0. The sample mean is 19.49996, and the 95% confidence interval provides a range for the true population mean.

Which means for every fatality per incident falls between 11% to 27%. 
